import json
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
from pathlib import Path

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
VECTORS_PATH = "anchor_vectors.json"
INDEX_PATH = "anchor.index"
MODEL_NAME = "deepvk/USER-base"  # –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å
TOP_K = 3  # –ö–æ–ª-–≤–æ –±–ª–∏–∂–∞–π—à–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤

# === –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ===
model = SentenceTransformer(MODEL_NAME)

# === –ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ –∏ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö ===
if not Path(VECTORS_PATH).exists():
    raise FileNotFoundError(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {VECTORS_PATH}")
if not Path(INDEX_PATH).exists():
    raise FileNotFoundError(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {INDEX_PATH}")

with open(VECTORS_PATH, "r", encoding="utf-8") as f:
    anchor_data = json.load(f)

index = faiss.read_index(INDEX_PATH)

# === –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –±–ª–∏–∂–∞–π—à–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ ===
def search_similar_fragments(text: str):
    embedding = model.encode(text)
    embedding = embedding / np.linalg.norm(embedding)  # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    embedding = np.array([embedding]).astype("float32")

    distances, indices = index.search(embedding, TOP_K)

    for rank, (idx, dist) in enumerate(zip(indices[0], distances[0]), start=1):
        fragment = anchor_data[idx]["text"]
        print(f"\nüîπ –ë–ª–∏–∑–∫–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç #{rank} (—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: {1 - dist:.4f}):\n{fragment.strip()}\n")

# === –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫ ===
if __name__ == "__main__":
    print("–ï—Å–ª–∏ —Ç—ã, —Å–ª–µ–¥—É—è –ø—Ä–∞–≤–æ–º—É —Ä–∞–∑—É–º—É, –±—É–¥–µ—à—å —Å—Ç–∞—Ä–∞—Ç–µ–ª—å–Ω–æ, —Ä–µ–≤–Ω–æ—Å—Ç–Ω–æ –∏ –ª—é–±–æ–≤–Ω–æ –æ—Ç–Ω–æ—Å–∏—Ç—å—Å—è –∫ –¥–µ–ª—É, –∫–æ—Ç–æ—Ä—ã–º —Ç—ã –≤ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç –∑–∞–Ω—è—Ç, –∏, –≥–ª—è–¥—è –ø–æ —Å—Ç–æ—Ä–æ–Ω–∞–º, –±—É–¥–µ—à—å –±–ª—é—Å—Ç–∏ —á–∏—Å—Ç–æ—Ç—É —Å–≤–æ–µ–≥–æ –≥–µ–Ω–∏—è, –∫–∞–∫ –±—É–¥—Ç–æ —É–∂–µ –ø–æ—Ä–∞ —Å –Ω–∏–º —Ä–∞—Å—Å—Ç–∞—Ç—å—Å—è, –µ—Å–ª–∏ —Ç—ã –±—É–¥–µ—à—å –ø–æ—Å—Ç—É–ø–∞—Ç—å —Ç–∞–∫, –Ω–∏—á–µ–≥–æ –Ω–µ –æ–∂–∏–¥–∞—è –∏ –Ω–µ –∏–∑–±–µ–≥–∞—è, –Ω–æ –¥–æ–≤–æ–ª—å—Å—Ç–≤—É—è—Å—å –Ω–∞–ª–∏—á–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é, —Å–æ–≥–ª–∞—Å–Ω–æ–π —Å –ø—Ä–∏—Ä–æ–¥–æ–π –∏ –≥–µ—Ä–æ–π—Å–∫–∏–º –ø—Ä–∞–≤–¥–æ–ª—é–±–∏–µ–º –≤–æ –≤—Å–µ–º, —á—Ç–æ —Ç—ã –≥–æ–≤–æ—Ä–∏—à—å –∏ –≤—ã—Å–∫–∞–∑—ã–≤–∞–µ—à—å, ‚Äì —Ç—ã –±—É–¥–µ—à—å —Ö–æ—Ä–æ—à–æ –∂–∏—Ç—å. –ò –Ω–∏–∫—Ç–æ –Ω–µ –≤ —Å–∏–ª–∞—Ö –ø–æ–º–µ—à–∞—Ç—å —ç—Ç–æ–º—É.")
    user_input = input("> ").strip()

    if not user_input:
        print("‚ö†Ô∏è –ü—É—Å—Ç–æ–π –≤–≤–æ–¥.")
    else:
        search_similar_fragments(user_input)
